{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read in all .json files\n",
    "import os\n",
    "DATA_LOC= f\"..{os.sep}Data{os.sep}Pending\"\n",
    "file_ext=\".json\"\n",
    "files=[]\n",
    "for file in os.listdir(DATA_LOC):\n",
    "    if file.endswith(file_ext):\n",
    "        files.append(os.path.join(DATA_LOC, file))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of Facts: 3059\n",
      "# of Misinformation: 21\n",
      "# of Opinion: 3784\n",
      "# of temporal: 252\n",
      "# of ignore: 3119\n",
      "# of not annotated: 7578\n",
      "# of errors: 47\n"
     ]
    }
   ],
   "source": [
    "#process a file\n",
    "import json\n",
    "facts=[]\n",
    "misinformation=[]\n",
    "temporal=[]\n",
    "ignore=[]\n",
    "opinion=[]\n",
    "none=[]\n",
    "errors=[]\n",
    "\n",
    "for file in files:\n",
    "    with open(file,encoding='utf8') as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "        sentences=data['sentences']\n",
    "\n",
    "        for sentence in sentences:\n",
    "            annotated=False\n",
    "            if sentence['fact'] and sentence['misinformation']:\n",
    "                errors.append(sentence)\n",
    "                annotated=True\n",
    "            elif sentence['misinformation'] and sentence['opinion']:\n",
    "                errors.append(sentence)\n",
    "                annotated=True\n",
    "            elif sentence['fact']:\n",
    "                facts.append(sentence)\n",
    "                annotated=True\n",
    "            elif sentence['misinformation']:\n",
    "                misinformation.append(sentence)\n",
    "                annotated=True\n",
    "            elif sentence['opinion']:\n",
    "                opinion.append(sentence)\n",
    "                annotated=True\n",
    "            if sentence['temporal']:\n",
    "                temporal.append(sentence)\n",
    "                annotated=True\n",
    "            if sentence['ignore']:\n",
    "                ignore.append(sentence)\n",
    "                annotated=True\n",
    "            if not annotated:\n",
    "                none.append(sentence)\n",
    "           \n",
    "    \n",
    "print(f'# of Facts: {len(facts)}')\n",
    "print(f'# of Misinformation: {len(misinformation)}')\n",
    "print(f'# of Opinion: {len(opinion)}')\n",
    "print(f'# of temporal: {len(temporal)}')\n",
    "print(f'# of ignore: {len(ignore)}')\n",
    "print(f'# of not annotated: {len(none)}')\n",
    "print(f'# of errors: {len(errors)}')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NN : 14.720383152556698\n",
      "NNP : 11.241019861952388\n",
      "IN : 10.015495140160587\n",
      "DT : 9.536554444287928\n",
      "JJ : 7.57853218763206\n",
      "NNS : 5.888153261022679\n",
      ", : 4.831666431891816\n",
      ". : 3.5920552190449357\n",
      "VBD : 3.2398929426679817\n",
      "VB : 3.225806451612903\n",
      "CC : 3.042682067896887\n",
      "TO : 2.7891252289054798\n",
      "RB : 2.7750387378504016\n",
      "CD : 2.5214818988589944\n",
      "VBN : 2.0143682208761797\n",
      "VBG : 1.9016762924355544\n",
      "VBZ : 1.7889843639949288\n",
      "PRP : 1.23961121284688\n",
      "VBP : 1.1973517396816453\n",
      "MD : 0.9719678828003944\n",
      "temporal: \n",
      " None\n",
      "NN : 14.670198145063667\n",
      "IN : 10.393286550346321\n",
      "DT : 9.04440743066743\n",
      "JJ : 8.043215101621021\n",
      "NNP : 7.512583167226425\n",
      "NNS : 6.442217549991354\n",
      ", : 4.449844815188998\n",
      "VB : 4.1949958587044565\n",
      "RB : 3.910111132348524\n",
      ". : 3.456844059743877\n",
      "CC : 3.1701389836987683\n",
      "TO : 2.981732790869126\n",
      "VBZ : 2.4520110313191164\n",
      "PRP : 2.4092328136234973\n",
      "VBD : 2.321856028543083\n",
      "VBP : 2.166216130118596\n",
      "VBG : 2.036061127342563\n",
      "VBN : 1.823990388553641\n",
      "MD : 1.5427463615760588\n",
      "CD : 1.2715142578889405\n",
      "opinion: \n",
      " None\n",
      "NN : 16.429699842022117\n",
      "IN : 10.42654028436019\n",
      "DT : 9.636650868878357\n",
      "JJ : 8.846761453396525\n",
      "NNP : 8.530805687203792\n",
      "NNS : 6.31911532385466\n",
      ", : 4.897314375987362\n",
      "VB : 3.7914691943127963\n",
      "TO : 3.6334913112164293\n",
      "VBZ : 3.4755134281200633\n",
      ". : 3.3175355450236967\n",
      "RB : 2.843601895734597\n",
      "CC : 2.6856240126382307\n",
      "VBG : 2.0537124802527646\n",
      "PRP : 1.8957345971563981\n",
      "VBD : 1.7377567140600316\n",
      "VBN : 1.579778830963665\n",
      "CD : 1.579778830963665\n",
      "VBP : 1.4218009478672986\n",
      "MD : 1.1058451816745656\n",
      "misinformation: \n",
      " None\n",
      "NN : 14.29758178079\n",
      "NNP : 11.335339229452227\n",
      "IN : 10.310103435350374\n",
      "DT : 9.355783160603389\n",
      "JJ : 7.150310508666889\n",
      "NNS : 6.277036541754044\n",
      ", : 4.989413326039165\n",
      "VBD : 3.3897618251628523\n",
      "VB : 3.2904800980660323\n",
      ". : 3.166884478618971\n",
      "CC : 2.9551509994022838\n",
      "RB : 2.8112938029966874\n",
      "TO : 2.7636790971441307\n",
      "CD : 2.3564214002775836\n",
      "VBG : 2.110243240231387\n",
      "VBZ : 1.9228236533649417\n",
      "VBN : 1.8772351052082383\n",
      "PRP : 1.505435168019127\n",
      "VBP : 1.3960226524430397\n",
      "MD : 1.0029480594474667\n",
      "facts: \n",
      " None\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\users\\live\\appdata\\local\\programs\\python\\python36\\lib\\genericpath.py\u001b[0m in \u001b[0;36misfile\u001b[1;34m(path)\u001b[0m\n\u001b[0;32m     29\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 30\u001b[1;33m         \u001b[0mst\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     31\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 2] The system cannot find the file specified: 'C:\\\\Users\\\\live/nltk_data'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-e5f463c0e6c5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'misinformation: \\n'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mpos_analysis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmisinformation\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'facts: \\n'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mpos_analysis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfacts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 41\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'none: \\n'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mpos_analysis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-12-e5f463c0e6c5>\u001b[0m in \u001b[0;36mpos_analysis\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mtokenized_text\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mpos_analysis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m     \u001b[0mtext\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mget_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[0mword_freq\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-12-e5f463c0e6c5>\u001b[0m in \u001b[0;36mget_text\u001b[1;34m(annotations)\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mtokenized_text\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mannotations\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m         \u001b[0mtokenized_text\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnltk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpos_tag\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnltk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mword_tokenize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0md\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'sentence'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mtokenized_text\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mpos_analysis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\live\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\nltk\\tag\\__init__.py\u001b[0m in \u001b[0;36mpos_tag\u001b[1;34m(tokens, tagset, lang)\u001b[0m\n\u001b[0;32m    158\u001b[0m     \u001b[1;33m:\u001b[0m\u001b[0mrtype\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    159\u001b[0m     \"\"\"\n\u001b[1;32m--> 160\u001b[1;33m     \u001b[0mtagger\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_get_tagger\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlang\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    161\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0m_pos_tag\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtagset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtagger\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlang\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    162\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\live\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\nltk\\tag\\__init__.py\u001b[0m in \u001b[0;36m_get_tagger\u001b[1;34m(lang)\u001b[0m\n\u001b[0;32m    104\u001b[0m         \u001b[0mtagger\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0map_russian_model_loc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    105\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 106\u001b[1;33m         \u001b[0mtagger\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mPerceptronTagger\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    107\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mtagger\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    108\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\live\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\nltk\\tag\\perceptron.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, load)\u001b[0m\n\u001b[0;32m    166\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mload\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    167\u001b[0m             AP_MODEL_LOC = \"file:\" + str(\n\u001b[1;32m--> 168\u001b[1;33m                 \u001b[0mfind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"taggers/averaged_perceptron_tagger/\"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mPICKLE\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    169\u001b[0m             )\n\u001b[0;32m    170\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mAP_MODEL_LOC\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\live\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\nltk\\data.py\u001b[0m in \u001b[0;36mfind\u001b[1;34m(resource_name, paths)\u001b[0m\n\u001b[0;32m    522\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mpath_\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpaths\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    523\u001b[0m         \u001b[1;31m# Is the path item a zipfile?\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 524\u001b[1;33m         \u001b[1;32mif\u001b[0m \u001b[0mpath_\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misfile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath_\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mpath_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\".zip\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    525\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    526\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mZipFilePathPointer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresource_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\live\\appdata\\local\\programs\\python\\python36\\lib\\genericpath.py\u001b[0m in \u001b[0;36misfile\u001b[1;34m(path)\u001b[0m\n\u001b[0;32m     28\u001b[0m     \u001b[1;34m\"\"\"Test whether a path is a regular file\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 30\u001b[1;33m         \u001b[0mst\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     31\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import statistics\n",
    "def get_text(annotations):\n",
    "    tokenized_text=[]  \n",
    "    for d in annotations:  \n",
    "        tokenized_text.append(nltk.pos_tag(nltk.word_tokenize(d['sentence'])))\n",
    "    return tokenized_text   \n",
    "def pos_analysis(data,name):    \n",
    "    text=get_text(data)\n",
    "\n",
    "    word_freq={}\n",
    "    pos_freq={}\n",
    "    lengths=[]\n",
    "    total=0\n",
    "    for sentence in text:\n",
    "        lengths.append(len(sentence))\n",
    "        for word in sentence:\n",
    "            total+=1\n",
    "            if word[0] not in word_freq:\n",
    "                word_freq[word[0].lower()] = 0 \n",
    "            word_freq[word[0].lower()] += 1\n",
    "            if word[1] not in pos_freq:\n",
    "                pos_freq[word[1]] = 0 \n",
    "            pos_freq[word[1]] += 1\n",
    "\n",
    "    sorted_word_freq = sorted(word_freq.items(), key=lambda kv: kv[1],reverse=True)\n",
    "    ''' \n",
    "    for x in sorted_word_freq[:10]:\n",
    "        print(f'{x}')\n",
    "    '''\n",
    "    sorted_pos_freq = sorted(pos_freq.items(), key=lambda kv: kv[1],reverse=True)\n",
    "    results={}\n",
    "    for x in sorted_pos_freq[:20]:\n",
    "        print(f'{x[0]} : {x[1]/total*100}')\n",
    "        results{}\n",
    "    \n",
    "   # return statistics.mean(lengths)\n",
    "     \n",
    "print('temporal: \\n',pos_analysis(temporal,'temporal'))\n",
    "print('opinion: \\n',pos_analysis(opinion,'opinion'))\n",
    "print('misinformation: \\n',pos_analysis(misinformation,'misinformation'))\n",
    "print('facts: \\n',pos_analysis(facts,'facts'))\n",
    "print('none: \\n',pos_analysis(none,'none'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\live\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\ensemble\\weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=1,\n",
       "            oob_score=False, random_state=0, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "import random,math\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "stemmer = PorterStemmer()\n",
    "def tokenize(text):\n",
    "    text=text.lower()\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "   # stems = []\n",
    "   # for item in tokens:\n",
    "   #     stems.append(PorterStemmer().stem(item))\n",
    "    #return stems\n",
    "    return tokens\n",
    "def tokenize_stem(text):\n",
    "    text=text.lower()\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    stems = []\n",
    "    for item in tokens:\n",
    "        stems.append(PorterStemmer().stem(item))\n",
    "    return stems\n",
    "\n",
    "def tokenize_pos(text):\n",
    "    text=text.lower()\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    pos=nltk.pos_tag(tokens)\n",
    "    tags=[]\n",
    "    for p in pos:\n",
    "        tags.append(p[1])\n",
    "    return tags\n",
    "\n",
    "def tokenize_pos_combo(text):\n",
    "    text=text.lower()\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    pos=nltk.pos_tag(tokens)\n",
    "    tags=[]\n",
    "    for p in pos:\n",
    "        tags.append(p[0])\n",
    "        tags.append(p[1])\n",
    "    return tags\n",
    "\n",
    "\n",
    "data =[]\n",
    "y=[]\n",
    "\n",
    "data.extend([d['sentence'] for d in facts])\n",
    "y.extend(['fact']*len(facts))\n",
    "#y.extend(['statement']*len(facts))\n",
    "\n",
    "#data.extend([d['sentence'] for d in opinion])\n",
    "#y.extend(['opinion']*len(opinion))\n",
    "#y.extend(['']*len(opinion))\n",
    "\n",
    "#data.extend([d['sentence'] for d in misinformation])\n",
    "#y.extend(['misinformation']*len(misinformation))\n",
    "#y.extend(['statement']*len(misinformation))\n",
    "\n",
    "\n",
    "#data.extend([d['sentence'] for d in ignore])\n",
    "#y.extend(['ignore']*len(ignore))\n",
    "\n",
    "data.extend([d['sentence'] for d in none])\n",
    "y.extend(['none']*len(none))\n",
    "\n",
    "labels = ['fact','opinion','misinformation','ignore','none']\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidfconverter = TfidfVectorizer(max_features=1500, min_df=1, max_df=0.9,ngram_range=(1, 3),tokenizer=tokenize,)\n",
    "\n",
    "X = tfidfconverter.fit_transform(data).toarray()\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "classifier = RandomForestClassifier(n_estimators=100, random_state=0)\n",
    "classifier.fit(X_train, y_train) \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "base tfidf in_df=5, max_df=0.7 with stop\n",
    "base run  = 70%\n",
    "base _ no stop 70%\n",
    "\n",
    "\n",
    "No enough misinformation examples to be of interest.\n",
    "Need to harvest more\n",
    "\n",
    "factual statements versus random declaritive 80%\n",
    "opinion vs declaritive sentence 70%\n",
    "fact vs opinion 70%\n",
    "\n",
    "going to try pos\n",
    "\n",
    "pos 1-2 points lower when used with tfidc , moving to language models\n",
    "\n",
    "\n",
    "going to try sentence structure\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               fact  opinion  misnformation  ignore  none\n",
      "fact            272        0              0       0   318\n",
      "opinion           0        0              0       0     0\n",
      "misnformation     0        0              0       0     0\n",
      "ignore            0        0              0       0     0\n",
      "none            134        0              0       0  1404\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "       fact       0.67      0.46      0.55       590\n",
      "       none       0.82      0.91      0.86      1538\n",
      "\n",
      "avg / total       0.78      0.79      0.77      2128\n",
      "\n",
      "0.7875939849624061\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "y_pred = classifier.predict(X_test)\n",
    "a =  confusion_matrix(y_test, y_pred, labels=labels)\n",
    "\n",
    "print(pd.DataFrame(a, index=labels, columns=labels))\n",
    "print(classification_report(y_test,y_pred))\n",
    "print(accuracy_score(y_test, y_pred))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=3, p=2,\n",
      "           weights='uniform')\n",
      "[[ 276  314]\n",
      " [ 194 1344]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "       fact       0.59      0.47      0.52       590\n",
      "       none       0.81      0.87      0.84      1538\n",
      "\n",
      "avg / total       0.75      0.76      0.75      2128\n",
      "\n",
      "0.7612781954887218\n",
      "SVC(C=0.025, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n",
      "[[   0  590]\n",
      " [   0 1538]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "       fact       0.00      0.00      0.00       590\n",
      "       none       0.72      1.00      0.84      1538\n",
      "\n",
      "avg / total       0.52      0.72      0.61      2128\n",
      "\n",
      "0.7227443609022557\n",
      "SVC(C=1, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma=2, kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\live\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 257  333]\n",
      " [ 101 1437]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "       fact       0.72      0.44      0.54       590\n",
      "       none       0.81      0.93      0.87      1538\n",
      "\n",
      "avg / total       0.79      0.80      0.78      2128\n",
      "\n",
      "0.7960526315789473\n",
      "GaussianProcessClassifier(copy_X_train=True,\n",
      "             kernel=1**2 * RBF(length_scale=1), max_iter_predict=100,\n",
      "             multi_class='one_vs_rest', n_jobs=1, n_restarts_optimizer=0,\n",
      "             optimizer='fmin_l_bfgs_b', random_state=None,\n",
      "             warm_start=False)\n",
      "[[ 305  285]\n",
      " [ 141 1397]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "       fact       0.68      0.52      0.59       590\n",
      "       none       0.83      0.91      0.87      1538\n",
      "\n",
      "avg / total       0.79      0.80      0.79      2128\n",
      "\n",
      "0.799812030075188\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=5,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best')\n",
      "[[ 192  398]\n",
      " [ 135 1403]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "       fact       0.59      0.33      0.42       590\n",
      "       none       0.78      0.91      0.84      1538\n",
      "\n",
      "avg / total       0.73      0.75      0.72      2128\n",
      "\n",
      "0.7495300751879699\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=5, max_features=1, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False)\n",
      "[[   0  590]\n",
      " [   0 1538]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "       fact       0.00      0.00      0.00       590\n",
      "       none       0.72      1.00      0.84      1538\n",
      "\n",
      "avg / total       0.52      0.72      0.61      2128\n",
      "\n",
      "0.7227443609022557\n",
      "MLPClassifier(activation='relu', alpha=1, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=(100,), learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=1000, momentum=0.9,\n",
      "       nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
      "       shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
      "       verbose=False, warm_start=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\live\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 239  351]\n",
      " [ 101 1437]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "       fact       0.70      0.41      0.51       590\n",
      "       none       0.80      0.93      0.86      1538\n",
      "\n",
      "avg / total       0.78      0.79      0.77      2128\n",
      "\n",
      "0.7875939849624061\n",
      "AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None,\n",
      "          learning_rate=1.0, n_estimators=50, random_state=None)\n",
      "[[ 268  322]\n",
      " [ 135 1403]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "       fact       0.67      0.45      0.54       590\n",
      "       none       0.81      0.91      0.86      1538\n",
      "\n",
      "avg / total       0.77      0.79      0.77      2128\n",
      "\n",
      "0.7852443609022557\n",
      "GaussianNB(priors=None)\n",
      "[[538  52]\n",
      " [812 726]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "       fact       0.40      0.91      0.55       590\n",
      "       none       0.93      0.47      0.63      1538\n",
      "\n",
      "avg / total       0.78      0.59      0.61      2128\n",
      "\n",
      "0.5939849624060151\n",
      "QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,\n",
      "               store_covariance=False, store_covariances=None, tol=0.0001)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\live\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\discriminant_analysis.py:682: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[546  44]\n",
      " [859 679]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "       fact       0.39      0.93      0.55       590\n",
      "       none       0.94      0.44      0.60      1538\n",
      "\n",
      "avg / total       0.79      0.58      0.59      2128\n",
      "\n",
      "0.5756578947368421\n"
     ]
    }
   ],
   "source": [
    "#run all\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.datasets import make_moons, make_circles, make_classification\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "classifiers = [\n",
    "    KNeighborsClassifier(3),\n",
    "    SVC(kernel=\"linear\", C=0.025),\n",
    "    SVC(gamma=2, C=1),\n",
    "    GaussianProcessClassifier(1.0 * RBF(1.0)),\n",
    "    DecisionTreeClassifier(max_depth=5),\n",
    "    RandomForestClassifier(max_depth=5, n_estimators=10, max_features=1),\n",
    "    MLPClassifier(alpha=1, max_iter=1000),\n",
    "    AdaBoostClassifier(),\n",
    "    GaussianNB(),\n",
    "    QuadraticDiscriminantAnalysis()]\n",
    "\n",
    "\n",
    "for c in classifiers:\n",
    "    print(c)\n",
    "    c.fit(X_train, y_train)\n",
    "    y_pred = c.predict(X_test)\n",
    "    print(confusion_matrix(y_test,y_pred))\n",
    "    print(classification_report(y_test,y_pred))\n",
    "    print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
